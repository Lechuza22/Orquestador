# app/main.py

import os
from orchestrator import inicializar_orquestador

# Inicializar el pipeline de LangChain
pipeline = inicializar_orquestador()

print("游 LLM Categorizer con Orquestador YAML")
print("游댌 Ingres치 tu pregunta (o escrib칤 'salir'):")

while True:
    pregunta = input("> ")

    if pregunta.strip().lower() == "salir":
        print("游녦 춰Hasta la pr칩xima!")
        break

    if not pregunta.strip():
        print("丘멆잺 Ingres치 una pregunta v치lida.")
        continue

    try:
        resultado = pipeline.invoke({"pregunta": pregunta})
        print("\n游늷 Respuesta generada por Gemini:")
        print(resultado["respuesta"])
    except Exception as e:
        print(f"[Error durante la ejecuci칩n]: {e}")
